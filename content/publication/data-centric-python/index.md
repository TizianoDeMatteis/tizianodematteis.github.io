---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: 'Productivity, Portability, Performance: Data-Centric Python'
subtitle: ''
summary: ''
authors:
- Alexandros Nikolaos Ziogas
- Timo Schneider
- Tal Ben-Nun
- Alexandru Calotoiu
- Tiziano De Matteis
- Johannes de Fine Licht
- Luca Lavarini
- Torsten Hoefler
tags: []
categories: []
date: '2021-11-01'
lastmod: 2021-10-19T12:03:25+02:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2021-10-19T10:03:24.991070Z'
publication_types:
- '1'
abstract: Python has become the de facto language for scientific computing. Programming
  in Python is highly productive, mainly due to its rich science-oriented software
  ecosystem built around the NumPy module. As a result, the demand for Python support
  in High Performance Computing (HPC) has skyrocketed. However, the Python language
  itself does not necessarily offer high performance. In this work, we present a workflow
  that retains Python's high productivity while achieving portable performance across
  different architectures. The workflow's key features are HPC-oriented language extensions
  and a set of automatic optimizations powered by a data-centric intermediate representation.
  We show performance results and scaling across CPU, GPU, FPGA, and the Piz Daint
  supercomputer (up to 23,328 cores), with 2.47x and 3.75x speedups over previous-best
  solutions, first-ever Xilinx and Intel FPGA results of annotated Python, and up
  to 93.16% scaling efficiency on 512 nodes.
publication: '*Proceedings of the International Conference for High Performance Computing,
  Networking, Storage and Analysis (SC21)*'
---
