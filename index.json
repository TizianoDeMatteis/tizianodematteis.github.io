[{"authors":["admin"],"categories":null,"content":"I received his MSc and Ph.D. from the University of Pisa. Currently, I am a PostDoc at the SPCL Group at ETH Zurich, working on reconfigurable hardware for High-Performance Computing.\nMy principal research interests are related to Parallel and Distributed Computing with a particular focus on FPGAs for HPC, Data Stream Processing, and Energy Awareness in Parallel Computing. In approaching these topics my main objective is to provide the application programmer with high-level abstractions and tools to develop complex parallel software with reduced time-to-market.\nI am a former member of Parallel Programming Model Group at University of Pisa.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I received his MSc and Ph.D. from the University of Pisa. Currently, I am a PostDoc at the SPCL Group at ETH Zurich, working on reconfigurable hardware for High-Performance Computing.\nMy principal research interests are related to Parallel and Distributed Computing with a particular focus on FPGAs for HPC, Data Stream Processing, and Energy Awareness in Parallel Computing. In approaching these topics my main objective is to provide the application programmer with high-level abstractions and tools to develop complex parallel software with reduced time-to-market.","tags":null,"title":"Tiziano De Matteis","type":"authors"},{"authors":["Tiziano De Matteis","Johannes de Fine Licht","and Torsten Hoefler"],"categories":null,"content":"","date":1604188800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604188800,"objectID":"bbecb3dc55ce7402ccd1073da16536e5","permalink":"/publication/fblas/","publishdate":"2020-08-25T09:09:50.338154Z","relpermalink":"/publication/fblas/","section":"publication","summary":"Spatial computing architectures pose an attractive alternative to mitigate control and data movement overheads typical of load-store architectures. In practice, these devices are rarely considered in the HPC community due to the steep learning curve, low productivity, and the lack of available libraries for fundamental operations. High-level synthesis (HLS) tools are facilitating hardware programming, but optimizing for these architectures requires factoring in new transformations and resources/performance trade-offs. We present FBLAS, an open-source HLS implementation of BLAS for FPGAs, that enables reusability, portability and easy integration with existing software and hardware codes. FBLAS' implementation allows scaling hardware modules to exploit on-chip resources, and module interfaces are designed to natively support streaming on-chip communications, allowing them to be composed to reduce off-chip communication. With FBLAS, we set a precedent for FPGA library design, and contribute to the toolbox of customizable hardware components necessary for HPC codes to start productively targeting reconfigurable platforms.","tags":null,"title":" FBLAS: Streaming Linear Algebra on FPGA","type":"publication"},{"authors":["Tiziano De Matteis","Gabriele Mencagli","Daniele De Sensi","Massimo Torquati","Marco Danelutto"],"categories":null,"content":"","date":1598346590,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598346590,"objectID":"d39667d7021ca0999bdcd08215f02034","permalink":"/publication/gasser/","publishdate":"2020-08-25T09:09:50.34027Z","relpermalink":"/publication/gasser/","section":"publication","summary":"Today's stream processing systems handle high-volume data streams in an efficient manner. To achieve this goal, they are designed to scale out on large clusters of commodity machines. However, despite the efficient use of distributed architectures, they lack support to co-processors like graphical processing units (GPUs) ready to accelerate data-parallel tasks. The main reason for this lack of integration is that GPU processing and the streaming paradigm have different processing models, with GPUs needing a bulk of data present at once while the streaming paradigm advocates a tuple-at-a-time processing model. This paper contributes to fill this gap by proposing Gasser, a system for offloading the execution of sliding-window operators on GPUs. The system focuses on completely general functions by targeting the parallel processing of non-incremental queries that are not supported by the few existing GPU-based streaming prototypes. Furthermore, Gasser provides an auto-tuning approach able to automatically find the optimal value of the configuration parameters (i.e., batch length and the degree of parallelism) needed to optimize throughput and latency with the given query and data stream. The experimental part assesses the performance efficiency of Gasser by comparing its peak throughput and latency against Apache Flink, a popular and scalable streaming system. Furthermore, we evaluate the penalty induced by supporting completely general queries against the performance achieved by the state-of-the-art solution specifically optimized for incremental queries. Finally, we show the speed and accuracy of the auto-tuning approach adopted by Gasser, which is able to self-configure the system by finding the right configuration parameters without manual tuning by the users.","tags":null,"title":"GASSER: An Auto-Tunable System for General Sliding-Window Streaming Operators on GPUs","type":"publication"},{"authors":["Tiziano De Matteis","Johannes de Fine Licht","Jakub Beránek","Torsten Hoefler"],"categories":null,"content":"","date":1572566400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572566400,"objectID":"99664b91eb5be80a18a57472d7962559","permalink":"/publication/smi/","publishdate":"2020-08-25T09:09:50.338601Z","relpermalink":"/publication/smi/","section":"publication","summary":"Distributed memory programming is the established paradigm used in high-performance computing (HPC) systems, requiring explicit communication between nodes and devices. When FPGAs are deployed in distributed settings, communication is typically handled either by going through the host machine, sacrificing performance, or by streaming across fixed device-to-device connections, sacrificing flexibility. We present Streaming~Message~Interface~(SMI), a communication model and API that unifies explicit message passing with a hardware-oriented programming model, facilitating minimal-overhead, flexible, and productive inter-FPGA communication. Instead of bulk transmission, messages are streamed across the network during computation, allowing communication to be seamlessly integrated into pipelined designs. We present a high-level synthesis implementation of SMI targeting a dedicated FPGA interconnect, exposing runtime-configurable routing with support for arbitrary network topologies, and implement a set of distributed memory benchmarks. Using SMI, programmers can implement distributed, scalable HPC programs on reconfigurable hardware, without deviating from best practices for hardware design.","tags":null,"title":"Streaming Message Interface: High-Performance DistributedMemory Programming on Reconfigurable Hardware","type":"publication"},{"authors":null,"categories":null,"content":"Streaming Message Interface is a a distributed memory HLS programming model for FPGAs that provides the convenience of message passing for HLS-programmed hardware devices. Instead of bulk transmission, typical of message passing model, with SMI messages are streamed across the network during computation, allowing communication to be seamlessly integrated into pipelined designs.\nThis repository contains an high-level synthesis implementation of SMI targeting OpenCL and Intel FPGAs, and all the applications used for the evaluation perfomed in the paper: \u0026ldquo;Streaming Message Interface: High-Performance Distributed Memory Programming on Reconfigurable Hardware\u0026rdquo;, Tiziano De Matteis, Johannes de Fine Licht, Jakub Beránek, and Torsten Hofler. To appear in Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis, 2019 (SC 2019).\nPlease refer to the project webpage and to the paper for a reference on how to use SMI for your own distributed FPGA programs.\n","date":1564617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564617600,"objectID":"50bf2468654b1ae0db8ee3c795bd43a3","permalink":"/software/smi-project/","publishdate":"2019-08-01T00:00:00Z","relpermalink":"/software/smi-project/","section":"software","summary":"Streaming Message Interface: High-Performance Distributed Memory Programming on Reconfigurable Hardware","tags":["FPGA"],"title":"SMI","type":"software"},{"authors":null,"categories":null,"content":"FBLAS is a porting of the BLAS numerical library (http://www.netlib.org/blas/) for Intel FPGA platform.\nFBLAS provides two layers of abstraction:\n  HLS modules, which can be integrated into existing hardware designs. They implement BLAS routines (DOT, GEMV, GEMM, etc.). Modules have been designed with compute performance in mind, exploiting the spatial parallelism and fast on-chip memory on FPGAs and have a streaming interface: data is received and produced using channels. In this way, they can be composed and communicate using on-chip resources rather than off-chip device RAM;\n  a high-level Host API conforming to the classical BLAS interface that allows the user to invoke routines directly from a host program. No prior knowledge on FPGA architecture and/or tools is needed. The user writes a standard OpenCL program: she is responsible to transferring data to and from the device, she can invoke the desired FBLAS routines working on the FPGA memory, and then she copies back the result from the device.\n  For further information on how to use the library, please refer to the project page.\n","date":1551398400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551398400,"objectID":"92e8fce1c7260723f54cdae45adf1bc3","permalink":"/software/fblas-project/","publishdate":"2019-03-01T00:00:00Z","relpermalink":"/software/fblas-project/","section":"software","summary":"BLAS implementation for Intel FPGA","tags":["FPGA"],"title":"FBLAS","type":"software"},{"authors":["Alessio Conte","Tiziano De Matteis","Daniele De Sensi","Roberto Grossi","Andrea Marino","Luca Versari"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"65a83033d6382e7eaa6d5cadb4b38895","permalink":"/publication/kdd-18/","publishdate":"2020-08-25T09:09:50.342093Z","relpermalink":"/publication/kdd-18/","section":"publication","summary":"This paper studies kplexes, a well known pseudo-clique model for network communities. In a kplex, each node can miss at most $k-1$ links. Our goal is to detect large communities in today's real-world graphs which can have hundreds of millions of edges. While many have tried, this task has been elusive so far due to its computationally challenging nature: kplexes and other pseudo-cliques are harder to find and more numerous than cliques, a well known hard problem. We present D2K, which is the first algorithm able to find large kplexes of very large graphs in just a few minutes. The good performance of our algorithm follows from a combination of graph-theoretical concepts, careful algorithm engineering and a high-performance implementation. In particular, we exploit the low degeneracy of real-world graphs, and the fact that large enough kplexes have diameter~2. We validate a sequential and a parallel/distributed implementation of D2K on real graphs with up to half a billion edges.","tags":["community discovery","graph enumeration","k-plexes","parallel programming"],"title":"D2K: Scalable Community Detection in Massive Networks via Small-Diameter k-Plexes","type":"publication"},{"authors":["Massimo Torquati","Tullio Menga","Tiziano De Matteis","Daniele De Sensi","Gabriele Mencagli"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"cc75b1949b9429f44ae6e0fed40dda56","permalink":"/publication/cafpdp-18/","publishdate":"2020-08-25T09:09:50.34312Z","relpermalink":"/publication/cafpdp-18/","section":"publication","summary":"In this work, we consider the C++ Actor Framework (CAF), a recent proposal that revamped the interest in building concurrent and distributed applications using the actor programming model in C++. CAF has been optimized for high-throughput computing, whereas message latency between actors is greatly influenced by the message data rate: at low and moderate rates the latency is higher than at high data rates. To this end, we propose a modification of the polling strategies in the work-stealing CAF scheduler, which can reduce message latency at low and moderate data rates up to two orders of magnitude without compromising the overall throughput and message latency at maximum pressure. The technique proposed uses a lightweight event notification protocol that is general enough to be used used to optimize the runtime of other frameworks experiencing similar issues.","tags":null,"title":"Reducing Message Latency and CPU Utilization in the CAF Actor Framework","type":"publication"},{"authors":["Daniele De Sensi","Tiziano De Matteis","Marco Danelutto"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"5ce69e053c4b9f4770ec1c0327514ebd","permalink":"/publication/nornir-fgcs-18/","publishdate":"2020-08-25T09:09:50.342344Z","relpermalink":"/publication/nornir-fgcs-18/","section":"publication","summary":"Self-adaptation is an emerging requirement in parallel computing. It enables the dynamic selection of resources toallocate to the application in order to meet performance and power consumption requirements. This is particularly relevant in Fog Applications, where data is generated by a number of devices at a varying rate, according to users’ activity. By dynamically selecting the appropriate number of resources it is possible, for example, to use at each time step the minimum amount of resources needed to process the incoming data. Implementing such kind of algorithms may be a complex task, due to low-level interactions with the underlying hardware and to non-intrusive and low-overhead monitoring of the applications. For these reasons, in this paper we propose Nornir, a C++-based framework, which can be used to enforce performance and power consumption constraints on parallel applications running on shared memory multicores. The framework can be easily customized by algorithm designers to implement new self-adaptive policies. By instrumenting the applications in the PARSEC benchmark, we provide to strategy designers a wide set of applications already interfaced to Nornir. In addition to this, to prove its flexibility, we implemented and compared several state-of-the-art existing policies, showing that Nornir can also be used to easily analyze different algorithms and to provide useful insights on them.","tags":["Self-adaptive","Power-aware","Quality of service","Data stream processing","Fog computing","Parallel computing"],"title":"Simplifying self-adaptive and power-aware computing with Nornir","type":"publication"},{"authors":["Marco Danelutto","Tiziano De Matteis","Daniele De Sensi","Gabriele Mencagli","Massimo Torquati","Marco Aldinucci","Peter Kilpatrick"],"categories":null,"content":"","date":1509494400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1509494400,"objectID":"ed7dcb03698cb92156a44ca2e0db2696","permalink":"/publication/rephrase-ijpp-17/","publishdate":"2020-08-25T09:09:50.351747Z","relpermalink":"/publication/rephrase-ijpp-17/","section":"publication","summary":"We discuss the extended parallel pattern set identified within the EU-funded project RePhrase as a candidate pattern set to support data intensive applications targeting heterogeneous architectures. The set has been designed to include three classes of pattern, namely (1) core patterns, modelling common, not necessarily data intensive parallelism exploitation patterns, usually to be used in composition; (2) high level patterns, modelling common, complex and complete parallelism exploitation patterns; and (3) building block patterns, modelling the single components of data intensive applications, suitable for use---in composition---to implement patterns not covered by the core and high level patterns. We discuss the expressive power of the RePhrase extended pattern set and results illustrating the performances that may be achieved with the FastFlow implementation of the high level patterns.","tags":null,"title":"The RePhrase Extended Pattern Set for Data Intensive Parallel Computing","type":"publication"},{"authors":["Daniele De Sensi","Tiziano De Matteis","Massimo Torquati","Gabriele Mencagli","Marco Danelutto"],"categories":null,"content":"","date":1506816000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1506816000,"objectID":"5b82308b71d5cbf5ae8dee9c17cd4b9b","permalink":"/publication/p-3-arsec-taco-17/","publishdate":"2020-08-25T09:09:50.352387Z","relpermalink":"/publication/p-3-arsec-taco-17/","section":"publication","summary":"High-level parallel programming is an active research topic aimed at promoting parallel programming methodologies that provide the programmer with high-level abstractions to develop complex parallel software with reduced time to solution. Pattern-based parallel programming is based on a set of composable and customizable parallel patterns used as basic building blocks in parallel applications. In recent years, a considerable effort has been made in empowering this programming model with features able to overcome shortcomings of early approaches concerning flexibility and performance. In this article, we demonstrate that the approach is flexible and efficient enough by applying it on 12 out of 13 PARSEC applications. Our analysis, conducted on three different multicore architectures, demonstrates that pattern-based parallel programming has reached a good level of maturity, providing comparable results in terms of performance with respect to both other parallel programming methodologies based on pragma-based annotations (i.e., Openmp and OmpSs) and native implementations (i.e., Pthreads). Regarding the programming effort, we also demonstrate a considerable reduction in lines of code and code churn compared to Pthreads and comparable results with respect to other existing implementations.","tags":["Parallel patterns","algorithmic skeletons","benchmarking","multicore programming","parsec"],"title":"Bringing Parallel Patterns Out of the Corner: The P$^3$ARSEC Benchmark Suite","type":"publication"},{"authors":["Massimo Torquati","Gabriele Mencagli","Maurizio Drocco","Marco Aldinucci","Tiziano De Matteis","Marco Danelutto"],"categories":null,"content":"","date":1504224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504224000,"objectID":"d2b02e0e1f827c00c641741c4591c8ef","permalink":"/publication/jsc-17/","publishdate":"2020-08-25T09:09:50.353856Z","relpermalink":"/publication/jsc-17/","section":"publication","summary":"This work studies the issues related to dynamic memory management in Data Stream Processing, an emerging paradigm enabling the real-time processing of live data streams. In this paper, we consider two streaming parallel patterns and we discuss different implementation variants related to how dynamic memory is managed. The results show that the standard mechanisms provided by modern C++ are not entirely adequate for maximizing the performance. Instead, the combined use of an efficient general purpose memory allocator, a custom allocator optimized for the pattern considered and a custom variant of the C++ shared pointer mechanism, provides a performance improvement up to 16% on the best case.","tags":null,"title":"On dynamic memory allocation in sliding-window parallel patterns for streaming analytics","type":"publication"},{"authors":["Gabriele Mencagli","Massimo Torquati","Marco Danelutto","Tiziano De Matteis"],"categories":null,"content":"","date":1504224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504224000,"objectID":"8a45bd2fd24f0d14d6ed7760b9679c85","permalink":"/publication/tpds-17/","publishdate":"2020-08-25T09:09:50.355382Z","relpermalink":"/publication/tpds-17/","section":"publication","summary":"Techniques to handle traffic bursts and out-of-order arrivals are of paramount importance to provide real-time sensor data analytics in domains like traffic surveillance, transportation management, healthcare and security applications. In these systems the amount of raw data coming from sensors must be analyzed by continuous queries that extract value-added information used to make informed decisions in real-time. To perform this task with timing constraints, parallelism must be exploited in the query execution in order to enable the real-time processing on parallel architectures. In this paper we focus on continuous preference queries, a representative class of continuous queries for decision making, and we propose a parallel query model targeting the efficient processing over out-of-order and bursty data streams. We study how to integrate punctuation mechanisms in order to enable out-of-order processing. Then, we present advanced scheduling strategies targeting scenarios with different burstiness levels, parameterized using the index of dispersion quantity. Extensive experiments have been performed using synthetic datasets and real-world data streams obtained from an existing real-time locating system. The experimental evaluation demonstrates the efficiency of our parallel solution and its effectiveness in handling the out-of-orderness degrees and burstiness levels of real-world applications.","tags":null,"title":"Parallel Continuous Preference Queries over Out-of-Order and Bursty Data Streams","type":"publication"},{"authors":["Tiziano De Matteis","Gabriele Mencagli"],"categories":null,"content":"","date":1491004800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1491004800,"objectID":"f1ce1bcb63348e3132841aca0741e848","permalink":"/publication/ijpp-17/","publishdate":"2020-08-25T09:09:50.347612Z","relpermalink":"/publication/ijpp-17/","section":"publication","summary":"The topic of Data Stream Processing is a recent and highly active research area dealing with the in-memory, tuple-by-tuple analysis of streaming data. Continuous queries typically consume huge volumes of data received at a great velocity. Solutions that persistently store all the input tuples and then perform off-line computation are impractical. Rather, queries must be executed continuously as data cross the streams. The goal of this paper is to present parallel patterns for window-based stateful operators, which are the most representative class of stateful data stream operators. Parallel patterns are presented ``à la'' Algorithmic Skeleton, by explaining the rationale of each pattern, the preconditions to safely apply it, and the outcome in terms of throughput, latency and memory consumption. The patterns have been implemented in the $$backslashmathtt FastFlow$$ FastFlow framework targeting off-the-shelf multicores. To the best of our knowledge this is the first time that a similar effort to merge the Data Stream Processing domain and the field of Structured Parallelism has been made.","tags":null,"title":"Parallel Patterns for Window-Based Stateful Operators on Data Streams: An Algorithmic Skeleton Approach","type":"publication"},{"authors":["Tiziano De Matteis","Gabriele Mencagli"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"6e5052bf2f09747eb021ef79930f8bd7","permalink":"/publication/dasp-pdp-17/","publishdate":"2020-08-25T09:09:50.344287Z","relpermalink":"/publication/dasp-pdp-17/","section":"publication","summary":"High-volume data streams are straining the limits of stream processing frameworks which need advanced parallel processing capabilities to withstand the actual incoming bandwidth. Parallel processing must be synergically integrated with elastic features in order dynamically scale the amount of utilized resources by accomplishing the Quality of Service goals in a costeffective manner. This paper proposes a control-theoretic strategy to drive the elastic behavior of latency-sensitive streaming operators in distributed environments. The strategy takes scaling decisions in advance by relying on a predictive model-based approach. Our ideas have been experimentally evaluated on a cluster using a real-world streaming application fed by synthetic and real datasets. The results show that our approach takes the strictly necessary reconfigurations while providing reduced resource consumption. Furthermore, it allows the operator to meet desired average latency requirements with a significant reduction in the experienced latency jitter.","tags":null,"title":"Elastic Scaling for Distributed Latency-sensitive Data Stream Operators","type":"publication"},{"authors":["Marco Danelutto","Tiziano De Matteis","Daniele De Sensi","Massimo Torquati"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"ae19811d2130b99e862c68a9f6f30695","permalink":"/publication/pdp-17/","publishdate":"2020-08-25T09:09:50.344851Z","relpermalink":"/publication/pdp-17/","section":"publication","summary":"Power-aware computing is gaining an increasing attention both in academic and industrial settings. The problem of guaranteeing a given QoS requirement (either in terms of performance or power consumption) can be faced by selecting and dynamically adapting the amount of physical and logical resources used by the application. In this study, we considered standard multicore platforms by taking as a reference approaches for power-aware computing two well-known dynamic reconfiguration techniques: Concurrency Throttling and Thread Packing. Furthermore, we also studied the impact of using simultaneous multithreading (e.g., Intel’s HyperThreading) in both techniques. In this work, leveraging on the applications of the PARSEC benchmark suite, we evaluate these techniques by considering performance-power trade-offs, resource efficiency, predictability and required programming effort. The results show that, according to the comparison criteria, these techniques complement each other.","tags":null,"title":"Evaluating Concurrency Throttling and Thread Packing on SMT Multicores","type":"publication"},{"authors":["Daniele De Sensi","Tiziano De Matteis","Marco Danelutto"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"fe1fbf406cbf29451c71aa0c5b184f92","permalink":"/publication/nornir-autodasp-17/","publishdate":"2020-08-25T09:09:50.353217Z","relpermalink":"/publication/nornir-autodasp-17/","section":"publication","summary":"A desirable characteristic of modern parallel applications is the ability to dynamically select the amount of resources to be used to meet requirements on performance or power consumption. In many cases, providing explicit guarantees on performance is of paramount importance. In streaming applications, this is related with the concept of elasticity, i.e. being able to allocate the proper amount of resources to match the current demand as closely as possible. Similarly, in other scenarios, it may be useful to limit the maximum power consumption of an application to do not exceed the available power budget. In this paper we propose Nornir, a customizable C++ framework for autonomic and power-aware parallel applications on shared memory multicore machines. Nornir can be used by autonomic strategy designers to implement new algorithms and by application users to enforce requirements on their applications.","tags":null,"title":"Nornir: A Customisable Framework for Autonomic and Power-Aware Applications","type":"publication"},{"authors":["Marco Danelutto","Tiziano De Matteis","Daniele De Sensi","Gabriele Mencagli","Massimo Torquati"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"f3f03193e0a1dd847ef460c159c03926","permalink":"/publication/sac-17/","publishdate":"2020-08-25T09:09:50.343751Z","relpermalink":"/publication/sac-17/","section":"publication","summary":"High-level parallel programming is a de-facto standard approach to develop parallel software with reduced time to development. High-level abstractions are provided by existing frameworks as pragma-based annotations in the source code, or through pre-built parallel patterns that recur frequently in parallel algorithms, and that can be easily instantiated by the programmer to add a structure to the development of parallel software. In this paper we focus on this second approach and we propose P3ARSEC, a benchmark suite for parallel pattern-based frameworks consisting of a representative subset of PARSEC applications. We analyse the programmability advantages and the potential performance penalty of using such high-level methodology with respect to hand-made parallelisations using low-level mechanisms. The results are obtained on the new Intel Knights Landing multicore, and show a significantly reduced code complexity with comparable performance.","tags":["Parallel Patterns","PARSEC Benchmarks","Intel KNL"],"title":"P$^3$ARSEC: Towards Parallel Patterns Benchmarking","type":"publication"},{"authors":["Tiziano De Matteis","Gabriele Mencagli"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"3839f31541432d02a18139d7078a4273","permalink":"/publication/jss-17/","publishdate":"2020-08-25T09:09:50.345966Z","relpermalink":"/publication/jss-17/","section":"publication","summary":"Abstract Data stream processing applications have a long running nature (24 hr/7 d) with workload conditions that may exhibit wide variations at run-time. Elasticity is the term coined to describe the capability of applications to change dynamically their resource usage in response to workload fluctuations. This paper focuses on strategies for elastic data stream processing targeting multicore systems. The key idea is to exploit Model Predictive Control, a control-theoretic method that takes into account the system behavior over a future time horizon in order to decide the best reconfiguration to execute. We design a set of energy-aware proactive strategies, optimized for throughput and latency QoS requirements, which regulate the number of used cores and the CPU frequency through the Dynamic Voltage and Frequency Scaling (DVFS) support offered by modern multicore CPUs. We evaluate our strategies in a high-frequency trading application fed by synthetic and real-world workload traces. We introduce specific properties to effectively compare different elastic approaches, and the results show that our strategies are able to achieve the best outcome. ","tags":["Data stream processing"],"title":"Proactive elasticity and energy awareness in data stream processing ","type":"publication"},{"authors":["Marco Danelutto","Tiziano De Matteis","Gabriele Mencagli","Massimo Torquati"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"39be793610c0065908ccf8b7050dae43","permalink":"/publication/seps-16/","publishdate":"2020-08-25T09:09:50.345358Z","relpermalink":"/publication/seps-16/","section":"publication","summary":"","tags":["Divide and Conquer","High-level parallel patterns"],"title":"A Divide-and-conquer Parallel Pattern Implementation for Multicores","type":"publication"},{"authors":["Tiziano De Matteis","Salvatore Di Girolamo","Gabriele Mencagli"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"e36183f8e7948e6aae82f1bb83b9f220","permalink":"/publication/ccpe-2016/","publishdate":"2020-08-25T09:09:50.347014Z","relpermalink":"/publication/ccpe-2016/","section":"publication","summary":"The emergence of real-time decision-making applications in domains like high-frequency trading, emergency management and service level analysis in communication networks, has led to the definition of new classes of queries. Skyline queries are a notable example. Their results consist of all the tuples whose attribute vector is not dominated (in the Pareto sense) by one of any other tuple. Because of their popularity, skyline queries have been studied in terms of both sequential algorithms and parallel implementations for multiprocessors and clusters. Within the Data Stream Processing paradigm, traditional database queries on static relations have been revised in order to operate on continuous data streams. Most of the past papers propose sequential algorithms for continuous skyline queries, whereas there exist very few works targeting implementations on parallel machines. This paper contributes to fill this gap by proposing a parallel implementation for multicore architectures. We propose: i) a parallelization of the eager algorithm based on the notion of Skyline Influence Time, ii) optimizations of the reduce phase and load-balancing strategies to achieve near-optimal speedup, iii) a set of experiments with both synthetic benchmarks and a real dataset in order to show our implementation effectiveness","tags":null,"title":"Continuous Skyline Queries on Multicore Architectures","type":"publication"},{"authors":["Marco Danelutto","Tiziano De Matteis","Gabriele Mencagli","Massimo Torquati"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"1699182e3be88fed2e15826d287c9a2c","permalink":"/publication/js-2016/","publishdate":"2020-08-25T09:09:50.346543Z","relpermalink":"/publication/js-2016/","section":"publication","summary":"Time-to-solution is an important metric when parallelizing existing code. The REPARA approach provides a systematic way to instantiate stream and data parallel patterns by annotating the sequential source code with Cpp11 attributes. Annotations are automatically transformed in a target parallel code that uses existing libraries for parallel programming (e.g., FastFlow). In this paper, we apply this approach for the parallelization of a data stream processing application. The description shows the effectiveness of the approach in easily and quickly prototyping several parallel variants of the sequential code by obtaining good overall performance in terms of both throughput and latency.","tags":null,"title":"Data stream processing via code annotations","type":"publication"},{"authors":["Tiziano De Matteis","Gabriele Mencagli"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"76d2e4a6a53e559c434f53286ff123bf","permalink":"/publication/ppopp-2016/","publishdate":"2020-08-25T09:09:50.354386Z","relpermalink":"/publication/ppopp-2016/","section":"publication","summary":"This paper addresses the problem of designing control strategies for elastic stream processing applications. Elasticity allows applications to rapidly change their configuration (e.g. the number of used resources) on-the-fly, in response to fluctuations of their workload. In this work we face this problem by adopting the Model Predictive Control technique, a control-theoretic method aimed at finding the optimal application configuration along a limited prediction horizon by solving an online optimization problem. Our control strategies are designed to address latency constraints, by using Queueing Theory models, and energy consumption by changing the number of used cores and the CPU frequency through the Dynamic Voltage and Frequency Scaling (DVFS) function of modern multi-core CPUs. The proactive capabilities, in addition to the latency- and energy-awareness, represent the novel features of our approach. Experiments performed using a high-frequency trading application show the effectiveness compared with state-of-the-art techniques.","tags":null,"title":"Keep Calm and React with Foresight: Strategies for Low-Latency and Energy-Efficient Elastic Data Stream Processing","type":"publication"},{"authors":["Tiziano De Matteis"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"cb87785293755b4d16cf3fb2bb151869","permalink":"/publication/dematteis-phd-16/","publishdate":"2020-08-25T09:09:50.354868Z","relpermalink":"/publication/dematteis-phd-16/","section":"publication","summary":"","tags":null,"title":"Parallel Patterns for Adaptive Data Stream Processing","type":"publication"},{"authors":["Tiziano De Matteis","Salvatore Di Girolamo","Gabriele Mencagli"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"48344f056b6b52153fbea7cf06784d03","permalink":"/publication/europar-2015/","publishdate":"2020-08-25T09:09:50.348118Z","relpermalink":"/publication/europar-2015/","section":"publication","summary":"","tags":null,"title":"A Multicore Parallelization of Continuous Skyline Queries on Data Streams","type":"publication"},{"authors":["Marco Danelutto","Tiziano De Matteis","Gabriele Mencagli","Massimo Torquati"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"759f1a5e0f2c34d3a2029f422b406328","permalink":"/publication/repara-2015/","publishdate":"2020-08-25T09:09:50.348562Z","relpermalink":"/publication/repara-2015/","section":"publication","summary":"","tags":null,"title":"Parallelizing High-Frequency Trading Applications by using C+ + 11 Attributes","type":"publication"},{"authors":["Tiziano De Matteis"],"categories":null,"content":"","date":1404172800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1404172800,"objectID":"18ec40aba8c43c1b77de869f45bfb60d","permalink":"/publication/hpcs-2014/","publishdate":"2020-08-25T09:09:50.350081Z","relpermalink":"/publication/hpcs-2014/","section":"publication","summary":"","tags":null,"title":"Autonomic Parallel Data Stream Processing","type":"publication"},{"authors":["Daniele Buono","Tiziano De Matteis","Gabriele Mencagli"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"eb2f485782cfdd5382fae6b52504eb3c","permalink":"/publication/ispa-2014/","publishdate":"2020-08-25T09:09:50.349575Z","relpermalink":"/publication/ispa-2014/","section":"publication","summary":"","tags":null,"title":"A High-Throughput and Low-Latency Parallelization of Window-based Stream Joins on Multicores","type":"publication"},{"authors":["Daniele Buono","Marco Danelutto","Tiziano De Matteis","Gabriele Mencagli","Massimo Torquati"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"1b16785c4fe9d08db7333227e9218fbb","permalink":"/publication/pdcn-2014/","publishdate":"2020-08-25T09:09:50.351279Z","relpermalink":"/publication/pdcn-2014/","section":"publication","summary":"The work proposes ffMDF, a lightweight dynamic run-time support able to achieve high performance in the execution of dense linear algebra kernels on shared-cache multi-core. ffMDF implements a dynamic macro-dataflow interpreter processing DAG graphs generated on-the-fly out of standard numeric kernel code. The experimental results demonstrate that the performance obtained using ffMDF on both fine-grain and coarse-grain problems is comparable with or even better than that achieved by de-facto standard solutions (notably PLASMA library), which use separate run-time supports specifically optimised for different computational grains on modern multi-core.","tags":null,"title":"A Lightweight Run-Time Support for Fast Dense Linear Algebra on Multi-Core","type":"publication"},{"authors":["Daniele Buono","Tiziano De Matteis","Gabriele Mencagli","Marco Vanneschi"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"18a8ba9190fd03534c9e256cf5c1d3ee","permalink":"/publication/pdp-2014/","publishdate":"2020-08-25T09:09:50.34905Z","relpermalink":"/publication/pdp-2014/","section":"publication","summary":"","tags":null,"title":"Optimizing Message-Passing on Multicore Architectures Using Hardware Multi-threading","type":"publication"},{"authors":["Tiziano De Matteis","Fabio Luporini","Gabriele Mencagli","Marco Vanneschi"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"27a9d42d328121561df567ae84be386b","permalink":"/publication/pdcn-2013/","publishdate":"2020-08-25T09:09:50.350824Z","relpermalink":"/publication/pdcn-2013/","section":"publication","summary":"The advent of multi-/many-core architectures demands efficient run-time supports to sustain parallel applications scalability. Synchronization mechanisms should be optimized in order to account for different scenarios, such as the interaction between threads executed on different cores as well as intra-core synchronization, i.e. involving threads executed on hardware contexts of the same core. In this perspective, we describe the design issues of two notable mechanisms for shared-memory parallel computations. We point out how specific architectural supports, like hardware cache coherence and core-to-core interconnection networks, make it possible to design optimized implementations of such mechanisms. In this paper we discuss experimental results on three representative architectures: a flagship Intel multi-core and two interesting network processors. The final result helps to untangle the complex implementation space of synchronization mechanisms.","tags":null,"title":"Evaluation of Architectural Supports for Fine-Grained Synchronization Mechanisms","type":"publication"}]